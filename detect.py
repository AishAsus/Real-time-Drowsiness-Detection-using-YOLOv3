# -*- coding: utf-8 -*-
"""Aiswarya_face.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17kb7e8iHnx5Ip8zvMF1hX9Orma7c1-1z
"""

# set OPENCV_OPENCL_DEVICE= 0
# set HL_GPU_DEVICE=1
import sys
import os
import cv2
import time
# sys.path.insert(0, "/content/drive/My Drive/yoloface")

from utils import *
from python_utils import *

model_cfg = r'C:\Users\ASHWARYA\Downloads\yoloface1\yoloface\cfg\yolov3-face.cfg'
model_weights = r'C:\Users\ASHWARYA\Downloads\yoloface1\yoloface\model-weights\yolov3-wider_16000.weights'
video = r'C:\Users\ASHWARYA\Pictures\Camera Roll\Combination.mp4'
output_dir = '/content/drive/My Drive/yoloface/dataset/out'

net = cv2.dnn.readNetFromDarknet(model_cfg, model_weights)
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)

import numpy as np
import cv2
# from PIL import Image 
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
model=load_model(r'C:\Users\ASHWARYA\Downloads\yoloface1\yoloface\model_trained_class.hdf5',compile=False)
class_list=['drowsy','non-drowsy']
class_list.sort()



cap=cv2.VideoCapture(0)
nos=0

while(True):
    
    # Capture frame-by-frame
    ret, frame = cap.read()
    frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5) 
    # print(ret)
    
    # cv2.imshow('new',frame)
    # cv2.waitKey(1)
    nos=nos+1
    if nos%5==0:
      # print(nos)
      if ret:
          start = time.process_time()
          blob = cv2.dnn.blobFromImage(frame, 1 / 255, (IMG_WIDTH, IMG_HEIGHT),
                                       [0, 0, 0], 1, crop=False)

           # Sets the input to the network
          net.setInput(blob)

           # Runs the forward pass to get output of the output layers
          outs = net.forward(['yolo_82','yolo_94','yolo_106'])

            # Remove the bounding boxes with low confidence
           # Runs the forward pass to get output of the output layers
          faces, crop_frame = post_process(frame, outs, CONF_THRESHOLD, NMS_THRESHOLD)           
              
          for i in range(np.shape(crop_frame)[0]):
    
              img= cv2.resize(crop_frame[i],(299,299))
              img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)         

  
              img = image.img_to_array(img)
              img=img/255              
              img = np.expand_dims(img, axis=0) 

              pred = model.predict(img)
              index = np.argmax(pred)

              pred_value=class_list[index]
              print(pred_value)
              print(time.process_time() - start)
              cv2.putText(frame, pred_value, (faces[0][0], faces[0][1]),cv2.FONT_HERSHEY_SIMPLEX, 0.7, COLOR_RED, 2)           
              cv2.imshow('Output',frame)
              cv2.waitKey(1)
          #key = cv2.waitKey(1)
          #if key == 27 or key == ord('q'):
          #    print('[i] ==> Interrupted by user!')
          #    break
     
cap.release()
cv2.destroyAllWindows()

print('==> All done!')
print('***********************************************************')

# crop_frame[i]

